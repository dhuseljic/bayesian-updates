{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Results of Online Bayesian Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "\n",
    "def load_results(exp_path: str):\n",
    "    exp_path = Path(exp_path)\n",
    "    json_file = exp_path / 'results.json'\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    config_file = exp_path / '.hydra' / 'config.yaml'\n",
    "    with open(config_file, 'r') as f:\n",
    "        args = OmegaConf.load(f)\n",
    "    return data, args\n",
    "\n",
    "\n",
    "def moving_average(a, n=3):\n",
    "    return np.convolve(a, np.ones(n), 'valid') / n\n",
    "\n",
    "\n",
    "def pad_array(arr1, arr2):\n",
    "    return np.pad(arr1, (0, len(arr2) - len(arr1)), constant_values=float('nan'))\n",
    "\n",
    "\n",
    "plot_path = Path('./plots/')\n",
    "os.makedirs(plot_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_metrics(experiments, metric_name, reweight_samples=[8]):\n",
    "    all_metric_values_baseline = []\n",
    "    all_metric_values_reweighted = { f'reweighted{i}': [] for i in reweight_samples}\n",
    "    for exp_name, exp_data in experiments.items():\n",
    "        res = exp_data['results']\n",
    "        all_metric_values_baseline.append([d['baseline_test_stats'][metric_name] for d in res])\n",
    "\n",
    "        for key in all_metric_values_reweighted:\n",
    "            accs = [d[f'{key}_test_stats'][metric_name] for d in res]\n",
    "            all_metric_values_reweighted[key].append(accs)\n",
    "\n",
    "    n_train_samples = np.array([d['n_train_samples'] for d in res])\n",
    "    divisor = 100 if metric_name == \"test_acc1\" else 1\n",
    "    all_metric_values_baseline = np.array(all_metric_values_baseline)/divisor\n",
    "    all_metric_values_reweighted = {key: np.array(val)/divisor for key, val in all_metric_values_reweighted.items()}\n",
    "    d = {\n",
    "        'n_train_samples': n_train_samples,\n",
    "        f'baseline_{metric_name}': all_metric_values_baseline,\n",
    "        f'reweighted_{metric_name}': all_metric_values_reweighted,\n",
    "    }\n",
    "    return d\n",
    "\n",
    "def retrieve_results(metric, reweight_samples, experiments_dict, test_alternative=\"greater\", pvalue=0.01):\n",
    "    max_reweight_samples = int(np.max(reweight_samples))\n",
    "    min_reweight_samples = int(np.min(reweight_samples))\n",
    "    exclude_samples = int(max_reweight_samples / min_reweight_samples)\n",
    "    results_dict = {}\n",
    "    auc_results_dict = {}\n",
    "    for param in experiments_dict:\n",
    "        results_dict[param] = {}\n",
    "        auc_results_dict[param] = {}\n",
    "        for param_val in experiments_dict[param]:\n",
    "            # Load results.results.\n",
    "            d = get_metrics(experiments_dict[param][param_val], metric, reweight_samples=reweight_samples)\n",
    "\n",
    "            # Create storages.\n",
    "            param_val = f\"${param_val}$\"\n",
    "            results_dict[param][param_val] = {}\n",
    "            auc_results_dict[param][param_val] = {}\n",
    "\n",
    "            # Load specific data.\n",
    "            n_train_samples = d['n_train_samples']\n",
    "            all_baseline_metrics = d[f'baseline_{metric}']\n",
    "            all_reweighted_metrics = d[f'reweighted_{metric}']\n",
    "            all_retrained_metrics = {f'retrained{(i*min_reweight_samples)}': np.array([pad_array(all_baseline_metrics[j, i:], n_train_samples) for j in range(all_baseline_metrics.shape[0])]) for i in range(1, 1 + max_reweight_samples // min_reweight_samples)}\n",
    "\n",
    "            # Exclude trailing samples.\n",
    "            n_train_samples = n_train_samples[:-exclude_samples]\n",
    "            all_baseline_metrics = all_baseline_metrics[:, :-exclude_samples]\n",
    "            all_reweighted_metrics = {key: val[:, :-exclude_samples] for key, val in all_reweighted_metrics.items()}\n",
    "            all_retrained_metrics = {key: val[:, :-exclude_samples] for key, val in all_retrained_metrics.items()}\n",
    "\n",
    "            # Store results in dictionaries.\n",
    "            results_dict[param][param_val]['n_train_samples'] = n_train_samples\n",
    "            results_dict[param][param_val]['metric_baseline'] = np.mean(all_baseline_metrics, 0)\n",
    "            auc_results_dict[param][param_val]['metric_baseline'] = f\"${np.round(np.mean(results_dict[param][param_val]['metric_baseline']), 3)}$\"\n",
    "            for metric_1, metric_2 in zip(all_reweighted_metrics, all_retrained_metrics):\n",
    "                results_dict[param][param_val][metric_1] = np.mean(all_reweighted_metrics[metric_1], 0)\n",
    "                results_dict[param][param_val][metric_2] = np.mean(all_retrained_metrics[metric_2], 0)\n",
    "                t_reweight = ttest_rel(np.mean(all_reweighted_metrics[metric_1], 1), np.mean(all_baseline_metrics, 1), alternative=test_alternative).pvalue <= pvalue\n",
    "                t_reweight = \"^{\\\\ast}\" if t_reweight else \"\\phantom{${^\\\\ast}$}\"\n",
    "                t_retrain = ttest_rel(np.mean(all_retrained_metrics[metric_2], 1), np.mean(all_baseline_metrics, 1), alternative=test_alternative).pvalue <= pvalue\n",
    "                t_retrain = \"{^\\\\ast}\" if t_retrain else \"\\phantom{${^\\\\ast}$}\"\n",
    "                auc_results_dict[param][param_val][metric_1] = f\"${np.round(np.mean(results_dict[param][param_val][metric_1]) - np.mean(results_dict[param][param_val]['metric_baseline']), 3)}{t_reweight}$\"\n",
    "                auc_results_dict[param][param_val][metric_2] = f\"${np.round(np.mean(results_dict[param][param_val][metric_2]) - np.mean(results_dict[param][param_val]['metric_baseline']), 3)}{t_retrain}$\"\n",
    "\n",
    "    return results_dict, auc_results_dict\n",
    "\n",
    "def main_table(metric_list, reweight_samples, experiments_dict, batch_size=[(32, 1)], test_alternative_list=\"greater\", pvalue=0.01):\n",
    "    max_reweight_samples = int(np.max(reweight_samples))\n",
    "    min_reweight_samples = int(np.min(reweight_samples))\n",
    "    exclude_samples = int(max_reweight_samples / min_reweight_samples)\n",
    "    results_dict = {}\n",
    "    auc_results_dict = {}\n",
    "    for param in experiments_dict:\n",
    "        results_dict[param] = {}\n",
    "        auc_results_dict[param] = {}\n",
    "        for param_val in experiments_dict[param]:\n",
    "            # Create storages.\n",
    "            #param_val = f\"${param_val}$\"\n",
    "            results_dict[param][param_val] = {}\n",
    "            auc_results_dict[param][param_val] = {}\n",
    "            for metric, test_alternative in zip(metric_list, test_alternative_list):\n",
    "                try:\n",
    "                    # Load results.results.\n",
    "                    d = get_metrics(experiments_dict[param][param_val], metric, reweight_samples=reweight_samples)\n",
    "\n",
    "\n",
    "                    # Load specific data.\n",
    "                    n_train_samples = d['n_train_samples']\n",
    "                    all_baseline_metrics = d[f'baseline_{metric}']\n",
    "                    all_reweighted_metrics = d[f'reweighted_{metric}']\n",
    "                    all_reweighted_metrics = {f\"cupd{b}\": all_reweighted_metrics[f\"reweighted{b}\"] for (b, _) in batch_size}\n",
    "                    all_retrained_metrics = {f'retr{b}': np.array([pad_array(all_baseline_metrics[j, i:], n_train_samples) for j in range(all_baseline_metrics.shape[0])]) for (b, i) in batch_size}\n",
    "\n",
    "                    # Exclude trailing samples.\n",
    "                    n_train_samples = n_train_samples[:-exclude_samples]\n",
    "                    all_baseline_metrics = all_baseline_metrics[:, :-exclude_samples]\n",
    "                    all_reweighted_metrics = {key: val[:, :-exclude_samples] for key, val in all_reweighted_metrics.items()}\n",
    "                    all_retrained_metrics = {key: val[:, :-exclude_samples] for key, val in all_retrained_metrics.items()}\n",
    "\n",
    "                    # Store results in dictionaries.\n",
    "                    results_dict[param][param_val]['n_train_samples'] = n_train_samples\n",
    "                    results_dict[param][param_val][metric + 'basl'] = np.mean(all_baseline_metrics, 0)\n",
    "                    if metric == \"training_time\":\n",
    "                        for metric_1, metric_2 in zip(all_reweighted_metrics, all_retrained_metrics):\n",
    "                            tr_reweighted = np.mean(all_reweighted_metrics[metric_1], -1).min()\n",
    "                            tr_retrained = np.mean(all_retrained_metrics[metric_2], -1).min()\n",
    "                            print(all_retrained_metrics[metric_2].mean(-1))\n",
    "                            #diff = np.round((tr_reweighted / tr_retrained - 1) * 100, 2)\n",
    "                            auc_results_dict[param][param_val]['z' + metric + metric_1] = f\"{tr_reweighted:.03f}\"\n",
    "                            auc_results_dict[param][param_val]['zz' + metric + metric_2] = f\"{tr_retrained:.03f}\"\n",
    "                    elif metric == \"test_prediction_time\":\n",
    "                        for metric_1 in all_reweighted_metrics:\n",
    "                            prediction_reweighted = np.mean(all_reweighted_metrics[metric_1], -1).min()\n",
    "                            print(all_reweighted_metrics[metric_1].mean(-1))\n",
    "                            auc_results_dict[param][param_val]['zzz' + metric + metric_1] = f\"{prediction_reweighted:.03f}\"\n",
    "                    else:\n",
    "                        auc_results_dict[param][param_val][metric + 'basl'] = f\"{np.mean(results_dict[param][param_val][metric + 'basl']):.03f}\"\n",
    "                        for metric_1, metric_2 in zip(all_reweighted_metrics, all_retrained_metrics):\n",
    "                            results_dict[param][param_val][metric + metric_1] = np.mean(all_reweighted_metrics[metric_1], 0)\n",
    "                            results_dict[param][param_val][metric + metric_2] = np.mean(all_retrained_metrics[metric_2], 0)\n",
    "                            t_reweight = ttest_rel(np.mean(all_reweighted_metrics[metric_1], 1), np.mean(all_baseline_metrics, 1), alternative=test_alternative).pvalue <= pvalue\n",
    "                            t_reweight = \"$^{\\\\ast}$\" if t_reweight else \"\\phantom{${^\\\\ast}$}\"\n",
    "                            t_retrain = ttest_rel(np.mean(all_retrained_metrics[metric_2], 1), np.mean(all_baseline_metrics, 1), alternative=test_alternative).pvalue <= pvalue\n",
    "                            t_retrain = \"${^\\\\ast}$\" if t_retrain else \"\\phantom{${^\\\\ast}$}\"\n",
    "                            diff = np.mean(results_dict[param][param_val][metric + metric_1]) - np.mean(results_dict[param][param_val][metric + 'basl'])\n",
    "                            auc_results_dict[param][param_val][metric + metric_1] = f\"{'+' if diff > 0 else '-'}{diff:.03f}{t_reweight}\"\n",
    "                            diff = np.mean(results_dict[param][param_val][metric + metric_2]) - np.mean(results_dict[param][param_val][metric + 'basl'])\n",
    "                            auc_results_dict[param][param_val][metric + metric_2] = f\"{'+' if diff > 0 else '-'}{diff:.03f}{t_retrain}\"\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    continue\n",
    "\n",
    "\n",
    "    return results_dict, auc_results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Tabular Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LETTER\n",
      "ensemble\n",
      "Found 10 experiments for draws=10\n",
      "[57.50945981 57.41137831 59.98422821 59.2546725  59.464089   60.0743186\n",
      " 57.19795027 58.67310795 60.02163472 59.95361576]\n",
      "[0.06173066 0.064171   0.06431121 0.06220998 0.06383737 0.06428764\n",
      " 0.06391139 0.06291374 0.0639794  0.06338143]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "draws & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_PENDIGITS_cat_entropybasl & test_auroc_PENDIGITS_cat_entropycupd32 & test_auroc_PENDIGITS_cat_entropyretr32 & test_auroc_PENDIGITS_dir_variancebasl & test_auroc_PENDIGITS_dir_variancecupd32 & test_auroc_PENDIGITS_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "10 & .542 & --.004\\phantom{${^\\ast}$} & +.028${^\\ast}$ & .675 & --.041\\phantom{${^\\ast}$} & +.003${^\\ast}$ & .762 & --.046\\phantom{${^\\ast}$} & +.009${^\\ast}$ & 2.928 & +.148\\phantom{${^\\ast}$} & --.416${^\\ast}$ & .004 & 57.198 & .062 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "mc_dropout\n",
      "Found 10 experiments for draws=1000\n",
      "[6.63901381 6.04548912 6.08047035 6.31591107 6.10903878 6.20612975\n",
      " 6.50249523 9.43340173 6.04963441 6.22227191]\n",
      "[0.20414248 0.24974409 0.19765182 0.24956055 0.23590696 0.22864377\n",
      " 0.22953645 0.25719224 0.22186447 0.26080797]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "draws & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_PENDIGITS_cat_entropybasl & test_auroc_PENDIGITS_cat_entropycupd32 & test_auroc_PENDIGITS_cat_entropyretr32 & test_auroc_PENDIGITS_dir_variancebasl & test_auroc_PENDIGITS_dir_variancecupd32 & test_auroc_PENDIGITS_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "1000 & .537 & --.006\\phantom{${^\\ast}$} & +.026${^\\ast}$ & .629 & --.014\\phantom{${^\\ast}$} & +.004${^\\ast}$ & .680 & --.019\\phantom{${^\\ast}$} & +.012${^\\ast}$ & 2.718 & +.161\\phantom{${^\\ast}$} & --.353${^\\ast}$ & .006 & 6.045 & .198 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "sngp\n",
      "Found 10 experiments for lmb=1\n",
      "[8.7265034  8.81246006 7.17288735 7.65894524 6.95588484 7.4187228\n",
      " 7.239905   7.82295883 6.85761542 8.1663779 ]\n",
      "[0.03990525 0.03991281 0.03895428 0.0421756  0.03850425 0.04165361\n",
      " 0.04093664 0.04319172 0.03776406 0.04430825]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "lmb & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_PENDIGITS_cat_entropybasl & test_auroc_PENDIGITS_cat_entropycupd32 & test_auroc_PENDIGITS_cat_entropyretr32 & test_auroc_PENDIGITS_dir_variancebasl & test_auroc_PENDIGITS_dir_variancecupd32 & test_auroc_PENDIGITS_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "1 & .543 & +.015$^{\\ast}$ & +.029${^\\ast}$ & .845 & +.007$^{\\ast}$ & +.015${^\\ast}$ & .833 & +.002$^{\\ast}$ & +.015${^\\ast}$ & 1.929 & --.051$^{\\ast}$ & --.095${^\\ast}$ & .118 & 6.858 & .038 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "sngp_sampling\n",
      "Found 10 experiments for draws=20000\n",
      "[8.70919242 8.69242783 8.86212245 8.67247962 9.64518198 8.98579198\n",
      " 8.77810414 8.64421676 8.68783584 8.77508668]\n",
      "[3.89502331 4.29785593 3.77687355 4.14570673 3.41957512 3.82697033\n",
      " 4.162745   4.02433028 4.22360672 4.22118816]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "draws & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_PENDIGITS_cat_entropybasl & test_auroc_PENDIGITS_cat_entropycupd32 & test_auroc_PENDIGITS_cat_entropyretr32 & test_auroc_PENDIGITS_dir_variancebasl & test_auroc_PENDIGITS_dir_variancecupd32 & test_auroc_PENDIGITS_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "20000 & .542 & --.006\\phantom{${^\\ast}$} & +.029${^\\ast}$ & .844 & --.010\\phantom{${^\\ast}$} & +.015${^\\ast}$ & .589 & +.027$^{\\ast}$ & +.015${^\\ast}$ & 1.909 & --.014$^{\\ast}$ & --.096${^\\ast}$ & .096 & 8.644 & 3.420 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "PENDIGITS\n",
      "ensemble\n",
      "Found 10 experiments for draws=10\n",
      "[59.34436268 59.78774221 58.74108883 59.61345235 59.50815487 56.87152826\n",
      " 59.95666901 60.39475604 60.0265859  56.83898311]\n",
      "[0.0354062  0.0351494  0.03478074 0.03490028 0.0356016  0.0354674\n",
      " 0.03548188 0.03539277 0.03572352 0.03540095]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "draws & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_LETTER_cat_entropybasl & test_auroc_LETTER_cat_entropycupd32 & test_auroc_LETTER_cat_entropyretr32 & test_auroc_LETTER_dir_variancebasl & test_auroc_LETTER_dir_variancecupd32 & test_auroc_LETTER_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "10 & .887 & +.000\\phantom{${^\\ast}$} & +.019${^\\ast}$ & .915 & --.007\\phantom{${^\\ast}$} & +.004${^\\ast}$ & .914 & --.005\\phantom{${^\\ast}$} & +.007${^\\ast}$ & .644 & +.003\\phantom{${^\\ast}$} & --.183${^\\ast}$ & .004 & 56.839 & .035 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "mc_dropout\n",
      "Found 10 experiments for draws=1000\n",
      "[6.63147504 6.43045923 6.62783618 6.73217486 6.77692255 6.5808719\n",
      " 6.72617217 6.45459179 6.49203924 6.18319492]\n",
      "[0.064457   0.0710148  0.06713607 0.066708   0.06668133 0.08270507\n",
      " 0.06636342 0.06776961 0.06556293 0.07030061]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "draws & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_LETTER_cat_entropybasl & test_auroc_LETTER_cat_entropycupd32 & test_auroc_LETTER_cat_entropyretr32 & test_auroc_LETTER_dir_variancebasl & test_auroc_LETTER_dir_variancecupd32 & test_auroc_LETTER_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "1000 & .890 & --.000\\phantom{${^\\ast}$} & +.021${^\\ast}$ & .888 & --.001\\phantom{${^\\ast}$} & +.006${^\\ast}$ & .823 & +.002$^{\\ast}$ & +.011${^\\ast}$ & .590 & +.012\\phantom{${^\\ast}$} & --.179${^\\ast}$ & .003 & 6.183 & .064 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "sngp\n",
      "Found 10 experiments for lmb=1\n",
      "[8.72402635 8.0753395  6.91066431 7.08504626 7.58590586 7.0067413\n",
      " 7.61207341 7.52353897 7.15395749 7.18872685]\n",
      "[0.0225686  0.02288915 0.02143461 0.02220269 0.02360921 0.02199225\n",
      " 0.02328662 0.02365967 0.02200567 0.02274286]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "lmb & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_LETTER_cat_entropybasl & test_auroc_LETTER_cat_entropycupd32 & test_auroc_LETTER_cat_entropyretr32 & test_auroc_LETTER_dir_variancebasl & test_auroc_LETTER_dir_variancecupd32 & test_auroc_LETTER_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "1 & .890 & +.013$^{\\ast}$ & +.021${^\\ast}$ & .941 & +.007$^{\\ast}$ & +.008${^\\ast}$ & .940 & +.004$^{\\ast}$ & +.009${^\\ast}$ & .502 & --.045$^{\\ast}$ & --.072${^\\ast}$ & .143 & 6.911 & .021 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "sngp_sampling\n",
      "Found 10 experiments for draws=20000\n",
      "[8.61066014 8.05524369 7.40513144 8.23315971 9.42138909 8.30024664\n",
      " 8.74159549 7.08862498 8.66684848 7.32577158]\n",
      "[0.88439527 1.47994699 1.42121307 1.48465559 0.83708997 1.51223326\n",
      " 0.83823417 1.35661645 0.84069378 1.358087  ]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "draws & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_LETTER_cat_entropybasl & test_auroc_LETTER_cat_entropycupd32 & test_auroc_LETTER_cat_entropyretr32 & test_auroc_LETTER_dir_variancebasl & test_auroc_LETTER_dir_variancecupd32 & test_auroc_LETTER_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "20000 & .890 & +.008$^{\\ast}$ & +.021${^\\ast}$ & .941 & +.002\\phantom{${^\\ast}$} & +.008${^\\ast}$ & .920 & +.001\\phantom{${^\\ast}$} & +.012${^\\ast}$ & .505 & --.049$^{\\ast}$ & --.071${^\\ast}$ & .040 & 7.089 & .837 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "MNIST\n",
      "ensemble\n",
      "Found 10 experiments for draws=10\n",
      "[418.26549296 425.89023247 422.72101821 425.52170582 425.96927234\n",
      " 425.55714641 326.37248882 427.72513183 427.64023861 393.98874555]\n",
      "[2.60340077 2.61763816 2.62459487 2.61959957 2.6140447  2.61684034\n",
      " 2.68226154 2.62544004 2.6320601  2.70866349]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "draws & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_FashionMNIST_cat_entropybasl & test_auroc_FashionMNIST_cat_entropycupd32 & test_auroc_FashionMNIST_cat_entropyretr32 & test_auroc_FashionMNIST_dir_variancebasl & test_auroc_FashionMNIST_dir_variancecupd32 & test_auroc_FashionMNIST_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "10 & .909 & --.003\\phantom{${^\\ast}$} & +.023${^\\ast}$ & .813 & --.045\\phantom{${^\\ast}$} & +.018${^\\ast}$ & .857 & --.024\\phantom{${^\\ast}$} & +.012${^\\ast}$ & .464 & +.031\\phantom{${^\\ast}$} & --.209${^\\ast}$ & .031 & 326.372 & 2.603 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "mc_dropout\n",
      "Found 10 experiments for draws=1000\n",
      "[42.49228681 42.94036034 42.78018926 43.21334876 43.42928796 43.38840649\n",
      " 33.68167188 43.12250761 32.55927204 42.95686455]\n",
      "[13.40474364 13.4567202  13.53859495 13.47353246 13.49636984 13.50807326\n",
      " 13.43992469 13.43599033 13.41964593 13.44704853]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "draws & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_FashionMNIST_cat_entropybasl & test_auroc_FashionMNIST_cat_entropycupd32 & test_auroc_FashionMNIST_cat_entropyretr32 & test_auroc_FashionMNIST_dir_variancebasl & test_auroc_FashionMNIST_dir_variancecupd32 & test_auroc_FashionMNIST_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "1000 & .897 & --.001\\phantom{${^\\ast}$} & +.021${^\\ast}$ & .745 & --.005\\phantom{${^\\ast}$} & +.025${^\\ast}$ & .793 & --.009\\phantom{${^\\ast}$} & +.022${^\\ast}$ & .426 & +.012\\phantom{${^\\ast}$} & --.136${^\\ast}$ & .055 & 32.559 & 13.405 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "sngp\n",
      "Found 10 experiments for lmb=1\n",
      "[46.24707433 55.47622694 46.49130715 55.63789632 55.96418804 46.24310012\n",
      " 45.98592972 46.45506557 48.15789231 47.11319652]\n",
      "[2.22946199 2.53432858 2.28102509 2.50545098 2.5188694  2.29981389\n",
      " 2.23639916 2.27269877 2.26562191 2.28040022]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "lmb & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_FashionMNIST_cat_entropybasl & test_auroc_FashionMNIST_cat_entropycupd32 & test_auroc_FashionMNIST_cat_entropyretr32 & test_auroc_FashionMNIST_dir_variancebasl & test_auroc_FashionMNIST_dir_variancecupd32 & test_auroc_FashionMNIST_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "1 & .886 & +.006$^{\\ast}$ & +.025${^\\ast}$ & .921 & +.003$^{\\ast}$ & +.006${^\\ast}$ & .936 & +.003$^{\\ast}$ & +.005${^\\ast}$ & .423 & --.028$^{\\ast}$ & --.086${^\\ast}$ & .144 & 45.986 & 2.229 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "sngp_sampling\n",
      "Found 10 experiments for draws=20000\n",
      "[46.88490686 48.8559568  51.26483395 54.65070772 48.25917636 49.02026212\n",
      " 48.27719723 48.38877314 48.0600286  52.01065416]\n",
      "[ 5.21903646  9.18865793  6.02383722 12.22102418  9.06713078  5.89861622\n",
      "  6.00995626  5.48791844 10.43152635  8.82015908]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "draws & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_FashionMNIST_cat_entropybasl & test_auroc_FashionMNIST_cat_entropycupd32 & test_auroc_FashionMNIST_cat_entropyretr32 & test_auroc_FashionMNIST_dir_variancebasl & test_auroc_FashionMNIST_dir_variancecupd32 & test_auroc_FashionMNIST_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "20000 & .886 & +.005$^{\\ast}$ & +.025${^\\ast}$ & .920 & +.000\\phantom{${^\\ast}$} & +.005\\phantom{${^\\ast}$} & .890 & +.002\\phantom{${^\\ast}$} & +.008${^\\ast}$ & .424 & --.029$^{\\ast}$ & --.087${^\\ast}$ & .064 & 46.885 & 5.219 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "FashionMNIST\n",
      "ensemble\n",
      "Found 10 experiments for draws=10\n",
      "[422.34259685 316.81149437 424.85638775 428.36170077 425.4080761\n",
      " 427.8260825  426.78532962 424.4642223  427.32718391 424.34943039]\n",
      "[2.62213995 2.66568607 2.60976845 2.63880975 2.61561027 2.62933017\n",
      " 2.63525501 2.60137911 2.64529042 2.624966  ]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "draws & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_MNIST_cat_entropybasl & test_auroc_MNIST_cat_entropycupd32 & test_auroc_MNIST_cat_entropyretr32 & test_auroc_MNIST_dir_variancebasl & test_auroc_MNIST_dir_variancecupd32 & test_auroc_MNIST_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "10 & .712 & --.009\\phantom{${^\\ast}$} & +.016${^\\ast}$ & .666 & --.044\\phantom{${^\\ast}$} & --.003\\phantom{${^\\ast}$} & .711 & --.034\\phantom{${^\\ast}$} & --.000\\phantom{${^\\ast}$} & 1.117 & +.125\\phantom{${^\\ast}$} & --.160${^\\ast}$ & .031 & 316.811 & 2.601 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "mc_dropout\n",
      "Found 10 experiments for draws=1000\n",
      "[42.78556978 33.56868067 43.30052673 42.92574277 43.19027489 43.40771413\n",
      " 43.38583759 43.28015182 43.56351346 43.15960156]\n",
      "[13.45399219 13.45184844 13.4446736  13.47806714 13.4608357  13.43065337\n",
      " 13.33901783 13.4450595  13.45997218 13.42793776]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "draws & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_MNIST_cat_entropybasl & test_auroc_MNIST_cat_entropycupd32 & test_auroc_MNIST_cat_entropyretr32 & test_auroc_MNIST_dir_variancebasl & test_auroc_MNIST_dir_variancecupd32 & test_auroc_MNIST_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "1000 & .684 & --.001\\phantom{${^\\ast}$} & +.019${^\\ast}$ & .649 & --.005\\phantom{${^\\ast}$} & +.001\\phantom{${^\\ast}$} & .766 & --.012\\phantom{${^\\ast}$} & +.010${^\\ast}$ & 1.081 & +.018\\phantom{${^\\ast}$} & --.150${^\\ast}$ & .055 & 33.569 & 13.339 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "sngp\n",
      "Found 10 experiments for lmb=1\n",
      "[46.30836904 46.38109274 57.56724731 53.23560886 46.68533461 46.14067512\n",
      " 46.36933463 55.17670242 57.13601865 56.18735086]\n",
      "[2.25117486 2.29609487 2.3631526  2.47550776 2.30341588 2.26973302\n",
      " 2.27406485 2.51999861 2.56430758 2.5998229 ]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "lmb & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_MNIST_cat_entropybasl & test_auroc_MNIST_cat_entropycupd32 & test_auroc_MNIST_cat_entropyretr32 & test_auroc_MNIST_dir_variancebasl & test_auroc_MNIST_dir_variancecupd32 & test_auroc_MNIST_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "1 & .685 & +.006$^{\\ast}$ & +.018${^\\ast}$ & .762 & --.006\\phantom{${^\\ast}$} & +.001\\phantom{${^\\ast}$} & .863 & --.000\\phantom{${^\\ast}$} & +.006${^\\ast}$ & .923 & --.034$^{\\ast}$ & --.066${^\\ast}$ & .166 & 46.141 & 2.251 \\\\\n",
      "\\end{tabular}\n",
      "\n",
      "sngp_sampling\n",
      "Found 10 experiments for draws=20000\n",
      "[46.53644853 47.68666316 50.66762567 48.67477858 48.07728499 47.70085479\n",
      " 48.83753614 47.94089701 49.1583886  50.13445359]\n",
      "[ 5.08301419  6.49324173  8.13778664  8.28450199  9.21298517 22.23087049\n",
      "  7.99695146  7.13124939  8.05670011  8.71130276]\n",
      "\\begin{tabular}{llllllllllllllll}\n",
      "draws & test_acc1basl & test_acc1cupd32 & test_acc1retr32 & test_auroc_MNIST_cat_entropybasl & test_auroc_MNIST_cat_entropycupd32 & test_auroc_MNIST_cat_entropyretr32 & test_auroc_MNIST_dir_variancebasl & test_auroc_MNIST_dir_variancecupd32 & test_auroc_MNIST_dir_varianceretr32 & test_nllbasl & test_nllcupd32 & test_nllretr32 & ztraining_timecupd32 & zztraining_timeretr32 & zzztest_prediction_timecupd32 \\\\\n",
      "20000 & .685 & +.005$^{\\ast}$ & +.018${^\\ast}$ & .764 & --.009\\phantom{${^\\ast}$} & --.001\\phantom{${^\\ast}$} & .709 & --.010\\phantom{${^\\ast}$} & --.001\\phantom{${^\\ast}$} & .922 & --.030$^{\\ast}$ & --.067${^\\ast}$ & .058 & 46.536 & 5.083 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = ['ensemble', 'mc_dropout', 'sngp', 'sngp_sampling']\n",
    "reweight_samples = [16, 32, 64]\n",
    "datasets = ['LETTER', \"PENDIGITS\", \"MNIST\", \"FashionMNIST\"]\n",
    "ood_datasets = [\"PENDIGITS\", \"LETTER\", \"FashionMNIST\", \"MNIST\"]\n",
    "total_results_dict = {}\n",
    "evaluate_only_default = True\n",
    "\n",
    "for dataset, ood_dataset in zip(datasets, ood_datasets):\n",
    "    total_results_dict[dataset] = {}\n",
    "    print(dataset)\n",
    "    for model in models:\n",
    "        print(model)\n",
    "\n",
    "        # TODO:\n",
    "        root_path = Path(f'/path/to/model/{model}')\n",
    "\n",
    "        # Get experiment paths.\n",
    "        all_experiments = {}\n",
    "        if model == 'sngp':\n",
    "            default_parameters = {\n",
    "                'lmb': 1,\n",
    "                'norm_bound': 6 if \"MNIST\" in dataset else 1,\n",
    "                'num_inducing': 1024,\n",
    "                'kernel_scale': 1 if \"MNIST\" in dataset else 8,\n",
    "                'n_residual_layers': 6 if \"MNIST\" in dataset else 2\n",
    "            }\n",
    "            possible_parameters = {\n",
    "                'lmb': [1, 2, 5],\n",
    "                'norm_bound': [1, 6, 12] if \"MNIST\" in dataset else [0.5, 1, 2],\n",
    "                'num_inducing': [256, 1024, 2048],\n",
    "                'kernel_scale': [1, 8, 256],\n",
    "                'n_residual_layers': [6] if \"MNIST\" in dataset else [2]\n",
    "            }\n",
    "            for param in default_parameters:\n",
    "                all_experiments[param] = {}\n",
    "                param_value_list = [default_parameters[param]] if evaluate_only_default else possible_parameters[param]\n",
    "                for param_value in param_value_list:\n",
    "                    query_string = f'{dataset}-' \\\n",
    "                                   f'sngp-' \\\n",
    "                                   f'lmb{default_parameters[\"lmb\"]}-' \\\n",
    "                                   f'norm_bound{default_parameters[\"norm_bound\"]}-' \\\n",
    "                                   f'num_inducing{default_parameters[\"num_inducing\"]}-' \\\n",
    "                                   f'kernel_scale{default_parameters[\"kernel_scale\"]}-' \\\n",
    "                                   f'n_residual_layers{default_parameters[\"n_residual_layers\"]}-' \\\n",
    "                                   f'seed*'\n",
    "                    query_string = query_string.replace(param+str(default_parameters[param]), param+str(param_value))\n",
    "                    all_experiments[param][param_value] = sorted(list(root_path.glob(query_string)))\n",
    "                    if evaluate_only_default:\n",
    "                        break\n",
    "                if evaluate_only_default:\n",
    "                        break\n",
    "        elif model == 'sngp_sampling':\n",
    "            default_parameters = {\n",
    "                'draws': 20000,\n",
    "                'norm_bound':  6 if \"MNIST\" in dataset else 1,\n",
    "                'num_inducing': 1024,\n",
    "                'kernel_scale': 1 if \"MNIST\" in dataset else 8,\n",
    "                'n_residual_layers': 6 if \"MNIST\" in dataset else 2\n",
    "            }\n",
    "            possible_parameters = {\n",
    "                'draws': [1000, 10000, 20000],\n",
    "                'norm_bound': [1, 6, 12] if \"MNIST\" in dataset else [0.5, 1, 2],\n",
    "                'num_inducing': [256, 1024, 2048],\n",
    "                'kernel_scale': [1, 8, 256],\n",
    "                'n_residual_layers': [6] if \"MNIST\" in dataset else [2]\n",
    "            }\n",
    "            for param in default_parameters:\n",
    "                all_experiments[param] = {}\n",
    "                param_value_list = [default_parameters[param]] if evaluate_only_default else possible_parameters[param]\n",
    "                for param_value in param_value_list:\n",
    "                    query_string = f'{dataset}-' \\\n",
    "                                   f'sngp_sampling-' \\\n",
    "                                   f'draws{default_parameters[\"draws\"]}-' \\\n",
    "                                   f'norm_bound{default_parameters[\"norm_bound\"]}-' \\\n",
    "                                   f'num_inducing{default_parameters[\"num_inducing\"]}-' \\\n",
    "                                   f'kernel_scale{default_parameters[\"kernel_scale\"]}-' \\\n",
    "                                   f'n_residual_layers{default_parameters[\"n_residual_layers\"]}-' \\\n",
    "                                   f'seed*'\n",
    "                    query_string = query_string.replace(param+str(default_parameters[param]), param+str(param_value))\n",
    "                    all_experiments[param][param_value] = sorted(list(root_path.glob(query_string)))\n",
    "                    if evaluate_only_default:\n",
    "                        break\n",
    "                if evaluate_only_default:\n",
    "                        break\n",
    "        elif model == 'ensemble':\n",
    "            default_parameters = {\n",
    "                'draws': 10,\n",
    "                'n_residual_layers': 6 if \"MNIST\" in dataset else 2\n",
    "            }\n",
    "            possible_parameters = {\n",
    "                'draws': [5, 10, 20],\n",
    "                'n_residual_layers': [6] if \"MNIST\" in dataset else [2]\n",
    "            }\n",
    "            for param in default_parameters:\n",
    "                all_experiments[param] = {}\n",
    "                param_value_list = [default_parameters[param]] if evaluate_only_default else possible_parameters[param]\n",
    "                for param_value in param_value_list:\n",
    "                    query_string = f'{dataset}-' \\\n",
    "                                   f'ensemble-' \\\n",
    "                                   f'draws{default_parameters[\"draws\"]}-' \\\n",
    "                                   f'n_residual_layers{default_parameters[\"n_residual_layers\"]}-' \\\n",
    "                                   f'seed*'\n",
    "                    query_string = query_string.replace(param+str(default_parameters[param]), param+str(param_value))\n",
    "                    all_experiments[param][param_value] = sorted(list(root_path.glob(query_string)))\n",
    "                    if evaluate_only_default:\n",
    "                        break\n",
    "                if evaluate_only_default:\n",
    "                        break\n",
    "        elif model == 'mc_dropout':\n",
    "            default_parameters = {\n",
    "                'draws': 1000,\n",
    "                'dropout_rate': 0.2 if \"MNIST\" in dataset else 0.5,\n",
    "                'n_residual_layers': 6  if \"MNIST\" in dataset else 2\n",
    "            }\n",
    "            possible_parameters = {\n",
    "                'draws': [100, 500, 1000] ,\n",
    "                'dropout_rate': [0.1, 0.2, 0.5] if \"MNIST\" in dataset else [0.25, 0.5, 0.75],\n",
    "                'n_residual_layers': [6]  if \"MNIST\" in dataset else [2]\n",
    "            }\n",
    "            for param in default_parameters:\n",
    "                all_experiments[param] = {}\n",
    "                param_value_list = [default_parameters[param]] if evaluate_only_default else possible_parameters[param]\n",
    "                for param_value in param_value_list:\n",
    "                    query_string = f'{dataset}-' \\\n",
    "                                   f'mc_dropout-' \\\n",
    "                                   f'draws{default_parameters[\"draws\"]}-' \\\n",
    "                                   f'dropout_rate{default_parameters[\"dropout_rate\"]}-' \\\n",
    "                                   f'n_residual_layers{default_parameters[\"n_residual_layers\"]}-' \\\n",
    "                                   f'seed*'\n",
    "                    query_string = query_string.replace(param+str(default_parameters[param]), param+str(param_value))\n",
    "                    all_experiments[param][param_value] = sorted(list(root_path.glob(query_string)))\n",
    "                    if evaluate_only_default:\n",
    "                        break\n",
    "                if evaluate_only_default:\n",
    "                        break\n",
    "        # Load results of experiments.\n",
    "        experiments = {}\n",
    "        for param in all_experiments:\n",
    "            experiments[param] = {}\n",
    "            for param_val in all_experiments[param]:\n",
    "                experiments[param][param_val] = {}\n",
    "                for exp_path in all_experiments[param][param_val]:\n",
    "                    try:\n",
    "                        results, args = load_results(exp_path)\n",
    "                        experiments[param][param_val][exp_path] = {'results': results, 'args': args}\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        #experiments[param].pop(param_val, None)\n",
    "                print(f'Found {len(experiments[param][param_val])} experiments for {param}={param_val}')\n",
    "        metric_list = [\"test_acc1\", f\"test_auroc_{ood_dataset}_cat_entropy\", f\"test_auroc_{ood_dataset}_dir_variance\", \"test_nll\", \"training_time\", \"test_prediction_time\"]\n",
    "        alternative_list = ['greater', 'greater', 'greater', 'less', '', '']\n",
    "        results, auc_results = main_table(metric_list=metric_list, test_alternative_list=alternative_list, reweight_samples=reweight_samples, experiments_dict=experiments, pvalue=0.01)\n",
    "        total_results_dict[dataset][model] = results\n",
    "        for param in auc_results:\n",
    "            auc_results_param = pd.DataFrame(auc_results[param])\n",
    "            auc_results_param.index.name = param\n",
    "            print(\n",
    "                auc_results_param.T.style.to_latex()\n",
    "                .replace(\"\\{\", \"^{\").replace(\"\\}\", \"}\")\n",
    "                .replace(\"\\$\", \"$\").replace(\"\\\\textasciicircum\", \"\")\n",
    "                .replace(\"\\\\textbackslash ast\", \"\\\\ast\")\n",
    "                .replace(\" ^\", \"^\").replace(\"{ \", \"{\")\n",
    "                .replace(\"metric\\_baseline\", \"0\")\n",
    "                .replace(\" 0.\", \" .\")\n",
    "                .replace(\"+0.\", \"+.\")\n",
    "                .replace(\"-0.\", \"-.\")\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_PENDIGITS_dir_variance\n",
      "test_auroc_PENDIGITS_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_PENDIGITS_dir_variance\n",
      "test_auroc_PENDIGITS_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_PENDIGITS_dir_variance\n",
      "test_auroc_PENDIGITS_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_PENDIGITS_dir_variance\n",
      "test_auroc_PENDIGITS_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_LETTER_dir_variance\n",
      "test_auroc_LETTER_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_LETTER_dir_variance\n",
      "test_auroc_LETTER_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_LETTER_dir_variance\n",
      "test_auroc_LETTER_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_LETTER_dir_variance\n",
      "test_auroc_LETTER_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_FashionMNIST_dir_variance\n",
      "test_auroc_FashionMNIST_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_FashionMNIST_dir_variance\n",
      "test_auroc_FashionMNIST_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_FashionMNIST_dir_variance\n",
      "test_auroc_FashionMNIST_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_FashionMNIST_dir_variance\n",
      "test_auroc_FashionMNIST_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_MNIST_dir_variance\n",
      "test_auroc_MNIST_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_MNIST_dir_variance\n",
      "test_auroc_MNIST_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_MNIST_dir_variance\n",
      "test_auroc_MNIST_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_MNIST_dir_variance\n",
      "test_auroc_MNIST_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_PENDIGITS_dir_variance\n",
      "test_auroc_PENDIGITS_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_LETTER_dir_variance\n",
      "test_auroc_LETTER_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_FashionMNIST_dir_variance\n",
      "test_auroc_FashionMNIST_cat_entropy\n",
      "test_acc1\n",
      "test_nll\n",
      "test_auroc_MNIST_dir_variance\n",
      "test_auroc_MNIST_cat_entropy\n"
     ]
    }
   ],
   "source": [
    "fontsize = 12\n",
    "model_name_dict = {\"ensemble\": \"Ensemble\", \"mc_dropout\": \"Dropout\", \"sngp\": \"SNGP-LA\", \"sngp_sampling\": \"SNGP-MC\"}\n",
    "dataset_name_dict = {\"LETTER\": \"LETTER\", \"PENDIGITS\": \"PDIGITS\", \"MNIST\": \"MNIST\", \"FashionMNIST\": \"FMNIST\"}\n",
    "style_dict = {\"ensemble\": {\"color\": \"r\"},\n",
    "              \"mc_dropout\": {\"color\": \"g\"},\n",
    "              \"sngp\": {\"color\": \"b\"},\n",
    "              \"sngp_sampling\": {\"color\": \"m\"}}\n",
    "ood_dataset_dict = {\"LETTER\": \"PENDIGITS\", \"PENDIGITS\": \"LETTER\", \"MNIST\": \"FashionMNIST\", \"FashionMNIST\": \"MNIST\"}\n",
    "def get_metric_name(metric):\n",
    "    if metric == \"test_acc1\":\n",
    "        return \"ACC\"\n",
    "    elif metric == \"test_nll\":\n",
    "        return \"NLL\"\n",
    "    elif \"variance\" in metric:\n",
    "        return \"AUROC (variance)\"\n",
    "    elif \"entropy\" in metric:\n",
    "        return \"AUROC (entropy)\"\n",
    "    else:\n",
    "        return ValueError(\"Invalid metric!\")\n",
    "for dataset, dataset_dict in total_results_dict.items():\n",
    "    for model in [\"ensemble\", \"mc_dropout\", \"sngp\", \"sngp_sampling\"]:\n",
    "            for metric in [\"test_acc1\", \"test_nll\", f\"test_auroc_{ood_dataset_dict[dataset]}_dir_variance\", f\"test_auroc_{ood_dataset_dict[dataset]}_cat_entropy\"]:\n",
    "                print(metric)\n",
    "                try:\n",
    "                    plt.figure(figsize=(4.5, 2.8))\n",
    "                    plt.title(f\"{dataset_name_dict[dataset]}: {model_name_dict[model]}\")\n",
    "                    for param, param_dict in dataset_dict[model].items():\n",
    "                        for value, value_dict in param_dict.items():\n",
    "                            plt.fill_between(x=value_dict[\"n_train_samples\"], y1=value_dict[f\"{metric}basl\"],\n",
    "                                             y2=value_dict[f\"{metric}retr32\"], alpha=0.1, zorder=1, color=\"k\")\n",
    "                            plt.plot(value_dict[\"n_train_samples\"], value_dict[f\"{metric}basl\"], ls=\"--\",\n",
    "                                     **style_dict[model], label=f\"{model_name_dict[model]} (baseline)\", alpha=0.5)\n",
    "                            plt.plot(value_dict[\"n_train_samples\"], value_dict[f\"{metric}cupd32\"], zorder=2, ls=\"-\", marker=\".\", **style_dict[model],\n",
    "                                     label=f\"{model_name_dict[model]} (update)\", lw=1.5)\n",
    "                            plt.plot(value_dict[\"n_train_samples\"], value_dict[f\"{metric}retr32\"], ls=\"-\", **style_dict[model],\n",
    "                                     label=f\"{model_name_dict[model]} (retrain)\", alpha=0.5)\n",
    "                    plt.xlabel(\"# samples in $\\mathcal{D}$\", fontsize=fontsize)\n",
    "                    plt.ylabel(f\"{get_metric_name(metric)}\", fontsize=fontsize)\n",
    "                    plt.legend()\n",
    "                    plt.tight_layout()\n",
    "\n",
    "                    if \"entropy\" in metric:\n",
    "                        plt.savefig(f\"plots/absolute_auroc_entropy_{dataset_name_dict[dataset]}_{model_name_dict[model]}.pdf\")\n",
    "                    else:\n",
    "                        plt.savefig(f\"plots/absolute_{metric.split('_')[1]}_{dataset_name_dict[dataset]}_{model_name_dict[model]}.pdf\")\n",
    "                    plt.close()\n",
    "                except:\n",
    "                    plt.close()\n",
    "                    continue\n",
    "\n",
    "for dataset, dataset_dict in total_results_dict.items():\n",
    "    for metric in [\"test_acc1\", \"test_nll\", f\"test_auroc_{ood_dataset_dict[dataset]}_dir_variance\", f\"test_auroc_{ood_dataset_dict[dataset]}_cat_entropy\"]:\n",
    "        try:\n",
    "            plt.figure(figsize=(4.5, 4.2))\n",
    "            plt.title(f\"{dataset_name_dict[dataset]}\")\n",
    "            for model in [\"ensemble\", \"mc_dropout\", \"sngp\", \"sngp_sampling\"]:\n",
    "                #if \"test_auroc\"in metric:\n",
    "                #    metric = f\"test_auroc_{ood_dataset_dict[dataset]}{auroc_metric}\"\n",
    "                for param, param_dict in dataset_dict[model].items():\n",
    "                    for value, value_dict in param_dict.items():\n",
    "                        plt.plot(value_dict[\"n_train_samples\"], value_dict[f\"{metric}cupd32\"]-value_dict[f\"{metric}basl\"],\n",
    "                                 zorder=2, marker=\".\", ls=\"-\", **style_dict[model], lw=1.5)\n",
    "                        plt.plot(value_dict[\"n_train_samples\"], value_dict[f\"{metric}retr32\"]-value_dict[f\"{metric}basl\"], ls=\"-\", **style_dict[model],\n",
    "                                 alpha=0.5, label=f\"{model_name_dict[model]}\", zorder=1)\n",
    "            plt.axhline(y=0, lw=0.8, color=\"k\", zorder=0, ls=\"--\")\n",
    "            plt.xlabel(\"# samples in $\\mathcal{D}$\", fontsize=fontsize)\n",
    "            plt.ylabel(f\"$\\Delta${get_metric_name(metric)}\", fontsize=fontsize)\n",
    "            #plt.legend()\n",
    "            plt.tight_layout()\n",
    "            print(metric)\n",
    "            if \"entropy\" in metric:\n",
    "                plt.savefig(f\"plots/diff_auroc_entropy_{dataset_name_dict[dataset]}.pdf\")\n",
    "            else:\n",
    "                plt.savefig(f\"plots/diff_{metric.split('_')[1]}_{dataset_name_dict[dataset]}.pdf\")\n",
    "            plt.close()\n",
    "        except:\n",
    "            plt.close()\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('bayesian_reweighting')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94e35bdffcaba96bd39f0270552cff6c59bf2bce71b69b7da2980f6162717110"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
